{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrJ8YNYAo2WdEUeHer3RXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judeha/addnoise/blob/main/Apply_Noise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OLj1v8UQSIcW"
      },
      "outputs": [],
      "source": [
        "# Import datasets from hugging face\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "conll=load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "KoxbMFURScIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from copy import deepcopy\n",
        "# conll=deepcopy(conll)"
      ],
      "metadata": {
        "id": "cAkbCFueSpBJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "\n",
        "from bisect import bisect_left"
      ],
      "metadata": {
        "id": "bnXxSN5tSYAQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "path = ('/content/drive/My Drive/Dell Lab/')"
      ],
      "metadata": {
        "id": "bptC3oAGV7r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load substitution probabilities\n",
        "subst_prob = pd.read_csv(path + 'subst_prob.csv')\n",
        "\n",
        "with open(path + 'subst_cdf.json') as f:\n",
        "  subst_cdf = json.load(f)"
      ],
      "metadata": {
        "id": "Db6gUsUpV5U7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load insertion probabilities\n",
        "\n",
        "with open(path + 'alph.json') as f:\n",
        "  alph = json.load(f)\n",
        "\n",
        "with open(path + 'ALPH.json') as f:\n",
        "  ALPH = json.load(f)\n",
        "\n",
        "non_alph = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "           ':', ';', '<', '=', '>', '?', '@',\n",
        "           '[', '\\\\', ']',\n",
        "           '{', '|', '}', '~']"
      ],
      "metadata": {
        "id": "boY1daYBkP8n"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subst_prob)\n",
        "print(subst_cdf)"
      ],
      "metadata": {
        "id": "S4wThR2KXVhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_list = list(subst_prob.columns.values)\n",
        "char_list.pop(0)\n",
        "print(char_list)"
      ],
      "metadata": {
        "id": "TVI_M8vcXwKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEXT: is this a bad or good article?\n",
        "random.seed(42)\n",
        "\n",
        "# Substitution function\n",
        "def substitute(c: str):\n",
        "    if c in char_list:\n",
        "      # identifies insertion index to maintain order\n",
        "      i = bisect_left(subst_cdf[c], random.random())\n",
        "      return subst_cdf[c][i+1]\n",
        "    else: return c\n",
        "  \n",
        "# Insertion function \n",
        "def insert():\n",
        "  if random.random < 0.55:\n",
        "    i = bisect_left(alph, random.random())\n",
        "    if random.random < 0.75:\n",
        "      return alph[i+1]\n",
        "    else: return ALPH[i+1]\n",
        "  else:\n",
        "    return random.choice(non_alph)\n",
        "\n",
        "# Simulate deletion of spaces between words by combining\n",
        "def combine(text, index):\n",
        "  if index > 0:\n",
        "    word, label = text[index]\n",
        "    prev_word, prev_label = text[index-1]\n",
        "    new_word = prev_word + word\n",
        "    new_label = prev_label\n",
        "    return new_word, new_label\n",
        "  else: return text[index]"
      ],
      "metadata": {
        "id": "UNRX1UT6U7C5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise_to_word(word, label):\n",
        "  chars = list(word)\n",
        "  for i, count in enumerate(word):\n",
        "    if random.random() < 0.02:\n",
        "      chars[i] = ''\n",
        "      continue\n",
        "    if random.random() < subst_prob[i]:\n",
        "      chars[i] = substitute(i)\n",
        "    if random.random() < 0.02:\n",
        "      chars[i] = chars[i] + insert()\n",
        "\n",
        "    # insert space\n",
        "    if random.random() < 0.02:\n",
        "      chars[i] = chars[i] + ' '\n",
        "  return ''.join(chars), label"
      ],
      "metadata": {
        "id": "WhqLrfy5VC9l"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise_to_sentence(sentence: list):\n",
        "  for i in len(sentence):\n",
        "    if random.random < 0.02:\n",
        "      sentence[i-1] = combine(sentence, i)\n",
        "      del sentence[i]\n",
        "    # Add noise to each word\n",
        "    if sentence[i]:\n",
        "      sentence[i] = add_noise_to_word(sentence[i])\n",
        "    return sentence\n",
        "\n",
        "def add_noise(data):\n",
        "  return (add_noise_to_sentence(sentence) for sentence in data)"
      ],
      "metadata": {
        "id": "c0jVMcIrm5-7"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine tokens into text\n",
        "# from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "# corpus = conll['train']['tokens']\n",
        "\n",
        "# for i in range(len(corpus)):\n",
        "#   corpus[i] = TreebankWordDetokenizer().detokenize(corpus[i])\n",
        "\n",
        "# print(corpus)"
      ],
      "metadata": {
        "id": "eesRRgWkyoN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track words and labels\n",
        "conll_train, conll_val, conll_test = (\n",
        "    [\n",
        "        list(zip(sentence_words, sentence_labels))\n",
        "        for sentence_words, sentence_labels\n",
        "        in zip(conll[split]['tokens'], conll[split]['ner_tags'])\n",
        "    ]\n",
        "    for split in ('train', 'validation', 'test')\n",
        ")\n",
        "\n",
        "print(conll_train)"
      ],
      "metadata": {
        "id": "Z6yaiWILU9Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_train_noisy = add_noise(conll_train)\n",
        "conll_val_noisy = add_noise(conll_val)\n",
        "conll_test_noisy = add_noise(conll_test)"
      ],
      "metadata": {
        "id": "1dvmVB9R453o"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    0: 'O',\n",
        "    1: 'B-PER',\n",
        "    2: 'I-PER',\n",
        "    3: 'B-ORG',\n",
        "    4: 'I-ORG',\n",
        "    5: 'B-LOC',\n",
        "    6: 'I-LOC',\n",
        "    7: 'B-MISC',\n",
        "    8: 'I-MISC'\n",
        "}"
      ],
      "metadata": {
        "id": "sP17H-VxyuN8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "with open('noisy_conll_train.txt', 'w') as f:\n",
        "  for sentence in conll_train_noisy:\n",
        "    for word, label in sentence:\n",
        "      f.write(f'{word} {id2label[label]}\\n')\n",
        "    f.write('\\n')"
      ],
      "metadata": {
        "id": "BfP8QDamcjxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('noisy_conll-2003_val.txt', 'w') as f:\n",
        "    for sentence in conll_val_noisy:\n",
        "        for word, label in sentence:\n",
        "            f.write(f'{word} {id2label[label]}\\n')\n",
        "        f.write('\\n')\n",
        "with open('noisy_conll-2003_test.txt', 'w') as f:\n",
        "    for sentence in conll_test_noisy:\n",
        "        for word, label in sentence:\n",
        "            f.write(f'{word} {id2label[label]}\\n')\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "R2PSmLyZ6A8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}